# 分布式秒杀系统

本系统关注点只在于后端技术，暂不讨论前端的相关可行操作

秒杀系统的关键在于，如果在高并发的情况下，对于共享资源的保护，在保证线程安全的前提下，还要尽可能地减少锁的粒度，以下是从三个不同的角度来实现锁对于共享资源的保护

- 基于MySQL
- 基于Redis
- 基于ZooKeeper

首先，对于上面三种方案，在单机的情况下，使用多线程并发的情况，模拟高并发抢购的场景。

## 方案一：最简单MysSQL锁住资源

利用MySQL更改数据的时候，会使用行锁锁住资源，但是可能存在的一个问题是，瞬时的高并发访问MySQL数据库，会不会使得服务器崩溃呢？如果采用分布式存储数据，缓解单机数据库访问的压力，这肯定又会造成代码的复杂性，因为必须保证分布式数据库中数据的一致性。

关键SQL语句如下：

```sql
UPDATE goods SET count = count - buyNum where count >= buyNum and id = goodsId; 
```

## 方案二：Redis实现分布式锁

- Redis集群可以从缓解大量用户访问瞬时访问一个服务器的压力
- 基于内存的数据读写，性能优于MySQL数据库

组合下面几个Redis命令，来完成Redis锁：

```sql
redis > setnx  lockName exipreTime	//成功返回1，失败返回0
redis > getset lockName expireTime	//１.lockName存在返回旧值，否则抛出异常
									//2.设置lockName的新值为expireTime
redis > get lockNname				//返回lockName的过期
redis > del lockNname				//释放锁
```

setnx是实现Redis分布式秒杀系统的关键，如果当前lockName不存在，则获取锁成功，否则失败。

getset是一个关于键值lockName的get和set的原子操作，如果lockName不在抛出异常，反之返回lockName对应的旧值，并设置lockName的旧值。

由于redis指令是单线程串行执行的，所以同一时刻执行getset操作的线程A和B，只有一个线程能够通过get和getset得到相同的结果，而另一线程虽然成功执行getset操作，也只能乖乖地重新获取锁。

由于其他线程可以通过getset检测锁的过期时间，所以Redis分布式锁可以避免死锁。

Redis分布式锁的具体实现如下：

```java
public class RedisLock {
    private static JedisClusterUtil jedisClusterUtil = new JedisClusterUtil();
    private static Random random  = new Random(47);
    private static long interval  = 3000;
    private static int randomBase = 100; 

    public boolean tryLock(String mutex, long timeout){
        Long current = System.currentTimeMillis();
        timeout *= 1000;
        try{
            while (true){
                if((System.currentTimeMillis()-current) > timeout) {
                    break;
                }
                else{
                    if(innerTryLock(mutex)) {
                        return true;
                    }
                    else {
                        Thread.sleep(randomBase + random.nextInt(100));
                    }
                }
            }
        }catch (Exception e){
            e.printStackTrace();
        }

        return false;
    }

    public void releaseLock(String mutex){
        jedisClusterUtil._del(mutex);
    }

    private boolean innerTryLock(String mutex){
        try{
            long now = System.currentTimeMillis();
            String expireTime = String.valueOf(now + interval);
            if(jedisClusterUtil._setnx(mutex, expireTime) == 1){
                return true;
            }
            else{
                if(checkIfLockTimeout(mutex, now)){
                    String expect = jedisClusterUtil._get(mutex);
                    String preExpireTime = jedisClusterUtil._getSet(mutex, expireTime);
                    if(preExpireTime != null && preExpireTime.equals(expect)){
                        return true;
                    }
                }
                return false;
            }

        }catch (Exception e){
            e.printStackTrace();
        }
        return false;
    }


    private boolean checkIfLockTimeout(String mutex, long timeStamp){
        return timeStamp > Long.valueOf(jedisClusterUtil._get(mutex));
    }
}
```

#### 存在的问题：

1. 分布式系统下时间的统一性
2. 多线程情况下，获取锁的线程通过getset设置的过期时间可能会被覆盖
3. 无法识别锁的拥有者，因为setnx和getset联合使用只能使用过期时间作为val


#### 其他方案

使用set新的命令实现

```
set(String key, String val, String n, String e, int expireTime);

key：键
val：值
n  ：可选参数，有NX，表示如果key不存在，则设置
e  ：可选参数，有PX，表示过期的设置
expireTime：表示key的过期时间
```

但是该方案还是无法解决分布式时间一致性的问题。


## 方案三：ZooKeeper实现分布式锁

网上有许多使用ZooKeeper实现分布式锁例子，但笔者发现存在不少的问题，现存可行的分布式锁实现方案如下代码。主要实现思路是：在高并发情况下，每个请求线程对父节点请求锁资源，由于ZooKeeper具有顺序创造子节点的功能，如果锁被其他线程获取，那么该线程子节点就监听上一个子节点，等待它释放完锁后通知自己。相比于所有子节点监听父节点引起的**“羊群效应”**，本方案的效率显然是更佳的。

有一点需要注意的是，在高并发下，子节点2发现子节点1存在，也就是子节点1占据着分布式锁，于是子节点2准备监听子节点1的释放，然而此时线程切换到子节点1释放锁，而子节点2不知道这一事实，并且执行监听子节点1的释放。于是子节点2监听了一个永远不会发生的事件，在子节点2之后的所有子节点均会被阻塞，于是整个分布式系统都被阻塞了。


```java
/*
    /zk-locks
             /milk
                  /number-1
                  /number-2
                  /number-3
                  .
                  .
                  .
            /apple
                  /number-1
                  /number-2
                  .
                  .
                  .
 */
public class ZookeeperLock {
    private static Logger logger = LoggerFactory.getLogger(ZookeeperLock.class);
    private static final String connectString = "127.0.0.1:2181";
    private static final String ROOT_PATH = "/zk-locks";
    private static final String NUMBER = "/number-";
    private static int sessionTimeout = 40000;
    private static int connectTimeout = 20000;
    private static RetryPolicy retryPolicy = new ExponentialBackoffRetry(5000, 5);
    private final CuratorFramework client;
    private final String mutex;
    private final String prefix;
    private final ThreadLocal<String> threadLocalPath;

    public ZookeeperLock(String mutex){
        this.mutex = "/" + mutex;
        this.prefix = ROOT_PATH + "/" + mutex + "/";
        this.threadLocalPath = new ThreadLocal<String>();
        client = CuratorFrameworkFactory.newClient(connectString, sessionTimeout, connectTimeout, retryPolicy);
        client.start(); //阻塞函数
    }


    public void close(){
        try{
            client.close();
        }catch (Exception e){
            e.printStackTrace();
        }
    }

    public void lock(){
        try{
            final String currentLock = client.create()
                    .creatingParentsIfNeeded()
                    .withMode(CreateMode.EPHEMERAL_SEQUENTIAL)
                    .forPath(ROOT_PATH + mutex + NUMBER);
            String index = currentLock.substring(currentLock.lastIndexOf("/")+1);
            List<String> brotherNodes = client.getChildren().forPath(ROOT_PATH + mutex);
            Collections.sort(brotherNodes);

            String prevNode = null;
            for(int i = brotherNodes.size()-1; i >= 0; --i){
                if(brotherNodes.get(i).compareTo(index) < 0){
                    prevNode = this.prefix + brotherNodes.get(i);
                    break;
                }
            }

//            System.out.println("**********************************************************");
//            System.out.println(Thread.currentThread().getName() + "-创建节点:" + index + ", 前一个节点是:" + prevNode);
//            System.out.println("**********************************************************");

            threadLocalPath.set(currentLock);
            if(prevNode == null){
                return;
            }
            else{
                final CountDownLatch latch = new CountDownLatch(1);
                final String watchPath = prevNode;
                final NodeCache cache = new NodeCache(client, watchPath, false);
                cache.start(true);
                cache.getListenable().addListener(new NodeCacheListener() {
                    @Override
                    public void nodeChanged() throws Exception {
                        latch.countDown();
                    }
                });

                //(bug) ... 添加prevNode节点为监听监听节点时，节点已被删除，此时的currentPath无法被唤醒
                // 解决方案如下
                try {
                    Stat stat = client.checkExists().forPath(prevNode);
                    if (stat == null) {
                        threadLocalPath.set(currentLock);
                        latch.countDown();
                    }
                }catch (Exception e){
                    logger.error("防止prevNode被删除，currentLock永远监听的Bug," + e.getMessage());
                    e.printStackTrace();
                }
                latch.await();
            }

        }catch (Exception e){
            logger.error("获取zookeeper锁异常: " + e.getMessage());
            e.printStackTrace();
        }
    }

    public void unlock(){
        try{
            String currentPath = threadLocalPath.get();
            if(currentPath != null && client.checkExists().forPath(currentPath) != null){
                client.delete().guaranteed().forPath(currentPath);
            }
        }catch (Exception e){
            logger.error("释放zookeeper分布式锁出错：" + e.getMessage());
            e.printStackTrace();
        }
    }


}
```

